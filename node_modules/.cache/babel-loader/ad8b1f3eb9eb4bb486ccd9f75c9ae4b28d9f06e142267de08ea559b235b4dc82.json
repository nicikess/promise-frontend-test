{"ast":null,"code":"const participants = [\n//Participant 1\n{\n  name: \"Participant 1\",\n  userStory: \"\\\"Starts by reading artifacts silently. (00:00-06:00)\\\n    Then he goes to Celonis and looks at the activities of the most common variants in the Variant Explorer and Process Explorer to familiarize, to get an initial understanding of the sequence of the process and the most common variants. He also makes a few assumptions about what he observes, for example \\\"\\\"so from Create Fine to Payment, this means that they received the fine directly on the place, right?\\\"\\\". (06:00-09:30)\\\n    Then, he looks at the research question to see what is expected and where to focus. (09:30-10:30)\\\n    He begins the analysis focusing on the Send for Credit Collection activity in Variant Explorer, which he had identified from the activity description as one circumstance for not paying. He filters for cases containing the Send for Credit Collection activity and explores variants. He then notices that some variants still contain the Payment activity and filters for cases without Payment. (10:30-14:00)\\\n    He mentions creating an OLAP table and looks at attributes to know what to put in, but quickly abandons that goal. (14:00-15:00) \\\n    [Replanning] Then, he decides to use the conformance checker as a fast solution to find reasons.\\\n    Since he doesn\\'t have a desired model, he uses the one discovered automatically by Celonis, removes the Send for Credit Collection activity to get the desired BPMN model and uses it as input for the conformance checker. Then he scrolls through the list of violations and stops at the first one, the Send for Credit Collection activity which was the one he wanted to drill down to. He performs root cause analysis for the Send for Credit Collection activity but doesn\\'t get any specific reason. Looks also at the other violations. (15:00-21:30)\\\n    [Replanning] He remembers about temporal constraints in the artifacts.\\\n    Applies throughput time selection filters to check the 90-day temporal constraint to find the answers. Then he moves on to check the temporal constraints about the prefecture. Checks the dismissal attribute and builds an OLAP table to check for dismissed cases. He\\'s satisfied with his findings. (21:30-33:00)\\\"\",\n  pmExpertise: \"Good\",\n  analysisExpertise: \"Basic\",\n  tool: [\"Celonis\"]\n},\n//Participant 2\n{\n  name: \"Participant 2\",\n  pmExpertise: \"Average\",\n  userStory: \"\\\"Starts by reading the artifacts to get an understanding of the data (00:00-04:00) \\\n    Then he reads the guiding question (04:00-06:00). \\\n    Then he goes to Disco and looks the process map and general statistics to get a basic understanding of the process flow. (06:00 - 08:00). Then he switches between the guiding question and the artifacts attempting to find an activity that corresponds to not paying. Since he cannot find it, he looks into the attributes but then asks for help. The interviewer clarifies the question (08:00 - 13:00). \\\n    He continues searching in the attributes for something that could indicate not paying [seems not to know where to visualize attributes in Disco or raw data. He is encouraged by the interviewer]. (13:00-17:00) \\\n    Then he filters for cases that do not include the Payment activity and compares the DFG of the filtered event log in with the original one to find patterns [but he does not seem to find any] (17:00-24:30) \\\n    He asks the interviewer to clarify once more the concept of circumstance and decides that \\\"\\\"no Payment activity\\\"\\\" is then a circumstance. (24:00-27:00) \\\n    He seems to struggle to find reasons for it by looking at the DFG and goes to Celonis to look into some example cases to find the reasons for not having a Payment activity. He performs root cause analysis. (27:00-31:30) Starts switching between Celonis and Disco and mentions having some difficulties with understanding the root cause analysis results (31:30-34:30) \\\n    Then he goes to the conformance overview and tries to mine the model with the Payment activity and compares the results of the conformance checking, going through the violation list but he is unsure about the result and asks to move on with the questions (34:30-39:00)\\\"\",\n  analysisExpertise: \"Average\",\n  tool: [\"Disco\", \"Celonis\"]\n},\n//Participant 3\n{\n  name: \"Participant 3\",\n  pmExpertise: \"Good\",\n  userStory: \"\\\"Starts by opening the event log as CSV to understand how the data is formatted and what it contains. (00:00-02:00)\\\n    Inspects the process map, looking at the activities and the main paths (02:00-06:30)\\\n    Opens the artifacts to have an idea of the context (06:30-11:00) \\\n    Then, she checks the guiding question and connects the \\\"\\\"reasons\\\"\\\" to the temporal constraints in the artifacts, which she thinks may hint to possible reasons (11:00-12:00)\\\n    She then explores the process map looking at the performance, finding bottlenecks (paths exhibiting long total and median duration) and rework. (13:00-18:00). She quickly checks the question to see if her findings answer it or not (18:00-18:30).\\\n    Then, she focuses on statistics [related to time] and starts looking at example cases in the variants, reflecting on the time constraints shown in the artifacts and the duration of transitions between activities [She never checks if the time constraints are respected or not] (18:30-27:00).\\\n    Notes down the first circumstance, i.e., that the police takes too long to send the fine (27:00-29:30)\\\n    Follows the same approach of looking at the variants and paths exhibiting long duration, finding the second circumstance in the delay between \\\"\\\"Add Penalty\\\"\\\" and \\\"\\\"Send for Credit Collection\\\"\\\" (19:30-32:00)\\\n    Then, she focuses on event attributes thinking that there must be something indicating how much the offender had to pay. She looks at the attribute distribution in Disco and notices that for one third of the cases the amount of the fine is empty. She thinks that the police is sending the fine without amount to pay and writes this as third circumstance (32:00-34:00).\\\n    \\\"\",\n  analysisExpertise: \"Average\",\n  tool: [\"Disco\"]\n},\n//Participant 4\n{\n  name: \"Participant 4\",\n  pmExpertise: \"Average\",\n  userStory: \"\\\"Starts by opening the event log as CSV to better understand the data and relate it to the question. He checks the guiding questions and decides to perform the analysis in Disco. (00:00-04:30)\\\n    In Disco, the participant starts by loading the event log for which he checks the artifacts again to decide which attributes he wants to include. He only loads a subset of the available attributes with the note to maybe adapt this later in the analysis, in case he notices that the selection is not enough to answer the question. (04:30-08:30)\\\n    After the event log is loaded, the participant reads and understands the activities in the process map. He is missing something and takes a few minutes to understand that there is no activity specific to missing payments and that he can find additional process variants not ending with the Payment activity by increasing the path-slider. (08:30-20:00)\\\n    After the analysis of the activities and variants, the participant explains to the interviewer how he would analyze the circumstances in more detail in PM4Py, in case he had more time (20:00-25:00).\\\n    To provide root causes of the circumstances, the participant uses ProM in which he tests a couple of methods: Inductive Visual Miner, Petri Net & Interactive Data-aware Heuristic Miner to identify \\\"\\\"this very explainable structure\\\"\\\" [understand the circumstances and provide root causes]. [He is not successful.] (25:00-29:00)\\\n    Afterwards, he decides to continues looking at the process map in Disco and takes notes regarding the three circumstances and his assumption regarding the root causes of the circumstances, solely based on the activities and variants displayed. (29:00-35:30)\\\n    The participant opens ProM again to test the Social Networking Mining in order to identify the most critical node for the variants leading to a missing payment. He create a Social Network (HoW) in ProM and notice that he missed to add a filter to the event log beforehand to be able to interpret results [not successful -  the interpretation is not clear and he is not able to identify any root causes]. (35:30 - 44:30)\\\n    The participant was stopped before performing a further analysis to continue with the questions & interview.\\\"\",\n  analysisExpertise: \"Average\",\n  tool: [\"Disco\", \"ProM\"]\n},\n//Participant 5\n{\n  name: \"Participant 5\",\n  pmExpertise: \"Average\",\n  analysisExpertise: \"Average\",\n  tool: [\"Celonis\"]\n},\n//Participant 6\n{\n  name: \"Participant 6\",\n  pmExpertise: \"Good\",\n  analysisExpertise: \"Good\",\n  tool: [\"Disco\"]\n},\n//Participant 7\n{\n  name: \"Participant 7\",\n  pmExpertise: \"Advanced\",\n  analysisExpertise: \"Average\",\n  tool: [\"Disco\"]\n},\n//Participant 8\n{\n  name: \"Participant 8\",\n  pmExpertise: \"Advanced\",\n  analysisExpertise: \"Good\",\n  tool: [\"Celonis\", \"ProM\"]\n},\n//Participant 9\n{\n  name: \"Participant 9\",\n  pmExpertise: \"Good\",\n  analysisExpertise: \"Good\",\n  tool: [\"Celonis\"]\n}];\nexport default participants;","map":{"version":3,"names":["participants","name","userStory","pmExpertise","analysisExpertise","tool"],"sources":["/Users/nicolaskesseli/NICOLAS_KESSELI/Programming/Lokal/promise-frontend/src/data/Participants.jsx"],"sourcesContent":["const participants = [\n  //Participant 1\n  {\n    name: \"Participant 1\",\n    userStory:\n    \"\\\"Starts by reading artifacts silently. (00:00-06:00)\\\n    Then he goes to Celonis and looks at the activities of the most common variants in the Variant Explorer and Process Explorer to familiarize, to get an initial understanding of the sequence of the process and the most common variants. He also makes a few assumptions about what he observes, for example \\\"\\\"so from Create Fine to Payment, this means that they received the fine directly on the place, right?\\\"\\\". (06:00-09:30)\\\n    Then, he looks at the research question to see what is expected and where to focus. (09:30-10:30)\\\n    He begins the analysis focusing on the Send for Credit Collection activity in Variant Explorer, which he had identified from the activity description as one circumstance for not paying. He filters for cases containing the Send for Credit Collection activity and explores variants. He then notices that some variants still contain the Payment activity and filters for cases without Payment. (10:30-14:00)\\\n    He mentions creating an OLAP table and looks at attributes to know what to put in, but quickly abandons that goal. (14:00-15:00) \\\n    [Replanning] Then, he decides to use the conformance checker as a fast solution to find reasons.\\\n    Since he doesn\\'t have a desired model, he uses the one discovered automatically by Celonis, removes the Send for Credit Collection activity to get the desired BPMN model and uses it as input for the conformance checker. Then he scrolls through the list of violations and stops at the first one, the Send for Credit Collection activity which was the one he wanted to drill down to. He performs root cause analysis for the Send for Credit Collection activity but doesn\\'t get any specific reason. Looks also at the other violations. (15:00-21:30)\\\n    [Replanning] He remembers about temporal constraints in the artifacts.\\\n    Applies throughput time selection filters to check the 90-day temporal constraint to find the answers. Then he moves on to check the temporal constraints about the prefecture. Checks the dismissal attribute and builds an OLAP table to check for dismissed cases. He\\'s satisfied with his findings. (21:30-33:00)\\\"\",\n    pmExpertise: \"Good\",\n    analysisExpertise: \"Basic\",\n    tool: [\"Celonis\"],\n  },\n\n  //Participant 2\n  {\n    name: \"Participant 2\",\n    pmExpertise: \"Average\",\n    userStory:\"\\\"Starts by reading the artifacts to get an understanding of the data (00:00-04:00) \\\n    Then he reads the guiding question (04:00-06:00). \\\n    Then he goes to Disco and looks the process map and general statistics to get a basic understanding of the process flow. (06:00 - 08:00). Then he switches between the guiding question and the artifacts attempting to find an activity that corresponds to not paying. Since he cannot find it, he looks into the attributes but then asks for help. The interviewer clarifies the question (08:00 - 13:00). \\\n    He continues searching in the attributes for something that could indicate not paying [seems not to know where to visualize attributes in Disco or raw data. He is encouraged by the interviewer]. (13:00-17:00) \\\n    Then he filters for cases that do not include the Payment activity and compares the DFG of the filtered event log in with the original one to find patterns [but he does not seem to find any] (17:00-24:30) \\\n    He asks the interviewer to clarify once more the concept of circumstance and decides that \\\"\\\"no Payment activity\\\"\\\" is then a circumstance. (24:00-27:00) \\\n    He seems to struggle to find reasons for it by looking at the DFG and goes to Celonis to look into some example cases to find the reasons for not having a Payment activity. He performs root cause analysis. (27:00-31:30) Starts switching between Celonis and Disco and mentions having some difficulties with understanding the root cause analysis results (31:30-34:30) \\\n    Then he goes to the conformance overview and tries to mine the model with the Payment activity and compares the results of the conformance checking, going through the violation list but he is unsure about the result and asks to move on with the questions (34:30-39:00)\\\"\",\n    analysisExpertise: \"Average\",\n    tool: [\"Disco\", \"Celonis\"],\n  },\n\n  //Participant 3\n  {\n    name: \"Participant 3\",\n    pmExpertise: \"Good\",\n    userStory:\"\\\"Starts by opening the event log as CSV to understand how the data is formatted and what it contains. (00:00-02:00)\\\n    Inspects the process map, looking at the activities and the main paths (02:00-06:30)\\\n    Opens the artifacts to have an idea of the context (06:30-11:00) \\\n    Then, she checks the guiding question and connects the \\\"\\\"reasons\\\"\\\" to the temporal constraints in the artifacts, which she thinks may hint to possible reasons (11:00-12:00)\\\n    She then explores the process map looking at the performance, finding bottlenecks (paths exhibiting long total and median duration) and rework. (13:00-18:00). She quickly checks the question to see if her findings answer it or not (18:00-18:30).\\\n    Then, she focuses on statistics [related to time] and starts looking at example cases in the variants, reflecting on the time constraints shown in the artifacts and the duration of transitions between activities [She never checks if the time constraints are respected or not] (18:30-27:00).\\\n    Notes down the first circumstance, i.e., that the police takes too long to send the fine (27:00-29:30)\\\n    Follows the same approach of looking at the variants and paths exhibiting long duration, finding the second circumstance in the delay between \\\"\\\"Add Penalty\\\"\\\" and \\\"\\\"Send for Credit Collection\\\"\\\" (19:30-32:00)\\\n    Then, she focuses on event attributes thinking that there must be something indicating how much the offender had to pay. She looks at the attribute distribution in Disco and notices that for one third of the cases the amount of the fine is empty. She thinks that the police is sending the fine without amount to pay and writes this as third circumstance (32:00-34:00).\\\n    \\\"\",\n    analysisExpertise: \"Average\",\n    tool: [\"Disco\"],\n  },\n\n  //Participant 4\n  {\n    name: \"Participant 4\",\n    pmExpertise: \"Average\",\n    userStory:\"\\\"Starts by opening the event log as CSV to better understand the data and relate it to the question. He checks the guiding questions and decides to perform the analysis in Disco. (00:00-04:30)\\\n    In Disco, the participant starts by loading the event log for which he checks the artifacts again to decide which attributes he wants to include. He only loads a subset of the available attributes with the note to maybe adapt this later in the analysis, in case he notices that the selection is not enough to answer the question. (04:30-08:30)\\\n    After the event log is loaded, the participant reads and understands the activities in the process map. He is missing something and takes a few minutes to understand that there is no activity specific to missing payments and that he can find additional process variants not ending with the Payment activity by increasing the path-slider. (08:30-20:00)\\\n    After the analysis of the activities and variants, the participant explains to the interviewer how he would analyze the circumstances in more detail in PM4Py, in case he had more time (20:00-25:00).\\\n    To provide root causes of the circumstances, the participant uses ProM in which he tests a couple of methods: Inductive Visual Miner, Petri Net & Interactive Data-aware Heuristic Miner to identify \\\"\\\"this very explainable structure\\\"\\\" [understand the circumstances and provide root causes]. [He is not successful.] (25:00-29:00)\\\n    Afterwards, he decides to continues looking at the process map in Disco and takes notes regarding the three circumstances and his assumption regarding the root causes of the circumstances, solely based on the activities and variants displayed. (29:00-35:30)\\\n    The participant opens ProM again to test the Social Networking Mining in order to identify the most critical node for the variants leading to a missing payment. He create a Social Network (HoW) in ProM and notice that he missed to add a filter to the event log beforehand to be able to interpret results [not successful -  the interpretation is not clear and he is not able to identify any root causes]. (35:30 - 44:30)\\\n    The participant was stopped before performing a further analysis to continue with the questions & interview.\\\"\",\n    analysisExpertise: \"Average\",\n    tool: [\"Disco\", \"ProM\"],\n  },\n\n  //Participant 5\n  {\n    name: \"Participant 5\",\n    pmExpertise: \"Average\",\n    analysisExpertise: \"Average\",\n    tool: [\"Celonis\"],\n  },\n\n  //Participant 6\n  {\n    name: \"Participant 6\",\n    pmExpertise: \"Good\",\n    analysisExpertise: \"Good\",\n    tool: [\"Disco\"],\n  },\n\n  //Participant 7\n  {\n    name: \"Participant 7\",\n    pmExpertise: \"Advanced\",\n    analysisExpertise: \"Average\",\n    tool: [\"Disco\"],\n  },\n\n  //Participant 8\n  {\n    name: \"Participant 8\",\n    pmExpertise: \"Advanced\",\n    analysisExpertise: \"Good\",\n    tool: [\"Celonis\", \"ProM\"],\n  },\n\n  //Participant 9\n  {\n    name: \"Participant 9\",\n    pmExpertise: \"Good\",\n    analysisExpertise: \"Good\",\n    tool: [\"Celonis\"],\n  },\n];\n\nexport default participants;\n"],"mappings":"AAAA,MAAMA,YAAY,GAAG;AACnB;AACA;EACEC,IAAI,EAAE,eAAe;EACrBC,SAAS,EACT;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6TAA6T;EACzTC,WAAW,EAAE,MAAM;EACnBC,iBAAiB,EAAE,OAAO;EAC1BC,IAAI,EAAE,CAAC,SAAS;AAClB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,SAAS;EACtBD,SAAS,EAAC;AACd;AACA;AACA;AACA;AACA;AACA;AACA,mRAAmR;EAC/QE,iBAAiB,EAAE,SAAS;EAC5BC,IAAI,EAAE,CAAC,OAAO,EAAE,SAAS;AAC3B,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,MAAM;EACnBD,SAAS,EAAC;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;EACHE,iBAAiB,EAAE,SAAS;EAC5BC,IAAI,EAAE,CAAC,OAAO;AAChB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,SAAS;EACtBD,SAAS,EAAC;AACd;AACA;AACA;AACA;AACA;AACA;AACA,mHAAmH;EAC/GE,iBAAiB,EAAE,SAAS;EAC5BC,IAAI,EAAE,CAAC,OAAO,EAAE,MAAM;AACxB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,SAAS;EACtBC,iBAAiB,EAAE,SAAS;EAC5BC,IAAI,EAAE,CAAC,SAAS;AAClB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,MAAM;EACnBC,iBAAiB,EAAE,MAAM;EACzBC,IAAI,EAAE,CAAC,OAAO;AAChB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,UAAU;EACvBC,iBAAiB,EAAE,SAAS;EAC5BC,IAAI,EAAE,CAAC,OAAO;AAChB,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,UAAU;EACvBC,iBAAiB,EAAE,MAAM;EACzBC,IAAI,EAAE,CAAC,SAAS,EAAE,MAAM;AAC1B,CAAC;AAED;AACA;EACEJ,IAAI,EAAE,eAAe;EACrBE,WAAW,EAAE,MAAM;EACnBC,iBAAiB,EAAE,MAAM;EACzBC,IAAI,EAAE,CAAC,SAAS;AAClB,CAAC,CACF;AAED,eAAeL,YAAY"},"metadata":{},"sourceType":"module","externalDependencies":[]}